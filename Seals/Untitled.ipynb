{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IACS summer camp - OpenCV\n",
    "===================\n",
    "\n",
    "[OpenCV](#openCV) is a python module that provides python bindings to a set of fast and efficient computer vision libraries written in C and C++. These bindings mean we can write code in python to access all of the openCV tools  without having to write any C or C++, while we still get the benefits of high sped processing of the compiled code.\n",
    "In this session we'll be introducing some of the tools available in the python module, and developing some code to automatically count seals visible in high resolution satellite imagery."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Installing openCV\n",
    "Windows\n",
    "Run the installation exe file and remember where you extracted the openCV files too.\n",
    "When the installer has finished go to the opencv/build/python/2.7 folder. Find the file called `cv2.pyd` and copy it the `/lib/site-packeges` subfolder of your python directory. eg. `C:/Python27/lib/site-packeges`.\n",
    "\n",
    "Mac\n",
    "\n",
    "`conda install -c https://conda.binstar.org/jjhelmus opencv`\n",
    "\n",
    "https://samkhan13.wordpress.com/2012/06/18/using-opencv-with-python-on-your-mac-os-x/\n",
    "\n",
    "Homebrew install: ```ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\"```\n",
    "\n",
    "1. ```brew tap homebrew/science```\n",
    "2. ```brew install opencv```\n",
    "3. ```sudo su```\n",
    "4. ```echo \"/usr/local/lib/python2.7/site-packages/\" > /Library/Python/2.7/site-packages/opencv.pth```\n",
    "\n",
    "###Importing modules\n",
    "\n",
    "You'll need to load several modules that we'll use in our seal detector. First we load the openCV package `cv2`. openCV images are stored as array of numbers, with rows and columns of the array representing the rows and columns of the image, with each value being the intensity or colour of a pixel.  openCV uses another module, `numpy`, to handle the arrays. We will import it ``as np``, which essentially just renames the module from `numpy` to `np` in our code. openCV needs `numpy` and assumes it has been renamed `np`, so this step is important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading an image\n",
    "Loading an image is simple in openCV, we use the `imread` function. The first argument (`file_name`) is the location of the image we want to load. It should be a string surrounded by quotation marks. The second argument (`flag`) tells openCV how we want to read the file.\n",
    "\n",
    "```python\n",
    "img = cv2.imread(<file_name>,<flag>)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Flags:**\n",
    "\n",
    "> - **cv2.IMREAD_COLOR** : Loads the image in color, but ignores the alpha (transparency) channel if present.\n",
    "> - **cv2.IMREAD_GRAYSCALE** : Loads the image in grayscale. \n",
    "> - **cv2.IMREAD_UNCHANGED** : Loads the image as it is, with alpha channel included.\n",
    "\n",
    "If you don't specify a flag then by default the image is loaded in its original form.\n",
    "\n",
    "When specifying a filename make sure you include the file extension. openCV will use this to work out what format the image is in and load it appropriately.\n",
    "\n",
    "\n",
    "**If you enter an invalid file name openCV won't tell you that there's a problem and the image created will be empty. Make sure you get the right path!**\n",
    "\n",
    "> Open CV supports reading:\n",
    "> \n",
    " - .bmp\n",
    " - .jpg\n",
    " - .tif\n",
    " - .png\n",
    ">\n",
    " >plus a few more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('testSeals.jpg',cv2.IMREAD_COLOR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image is stored as array called img. We can access the value of any pixel using its array index if we know its row and column position. If the image is in grayscale, the pixel has a single value, its intensity. If the image is in a color format such as rgb the pixel value is a tuple containing a value for the levels of red, green and blue hat make up the color at that pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get value of pixel at 100,100\n",
    "img[100,100]\n",
    "#Get value of pixel at 100,100 from blue channel\n",
    "img[100,100,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Displaying an image\n",
    "OpenCV provides functions for viewing the images we've loaded, but they can be a little confusing. Initially we need to create a window in which we'll display the image, and choose the image we want to display.\n",
    "```python\n",
    "cv2.imshow(<'window_name'>,<image>)\n",
    "```\n",
    "We use the `imshow` function with the first argument (`window_name`) being the name of the window (a string) and the second argument (`image`) being the image we want to display.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv2.imshow('Seals',img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run the code up to this point you'll see that an empty window is created, but our image doesn't show up yet. We need to tell python to draw the image and wait until we're done with it.  `waitKey()` tells openCV to draw the image an wait until we press any key before doing anything else.  The argument to this function is a time (in milliseconds) to wait for a key press before continuing anyway. 0 means wait forever.\n",
    "```python\n",
    "cv2.waitKey(<time>)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we're done with the image we can close the window using the `destroyAllWindows()` function. This line (and any that follow) won't be run until either a key has been pressed or `<time>` milliseconds have passed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Complete code example - displaying an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load the image\n",
    "img = cv2.imread('simpleBlobs.jpg',cv2.IMREAD_COLOR)\n",
    "#Create a window to display the image\n",
    "cv2.imshow('seal_image',img)\n",
    "#Draw the image and wait for user input\n",
    "cv2.waitKey(0)\n",
    "#When a key has ben pressed, destroy the window\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Saving an image\n",
    "```python\n",
    "cv2.imwrite('file_name',image)\n",
    "```\n",
    "To save an image we use the `imwrite` function. The first argument is the path to save the file as, including the extension (.jpg, .png, etc.), and the second argument is the image you'd like to save. If the just give the function the name of the file to save it will be saved in the directory you run python from.\n",
    "\n",
    "####Code example - Saving a copy of the seal image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('Seal_copy.png',img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##Blob Detection\n",
    "###The theory of blob detection\n",
    "\n",
    "**explain blob detection steps here**\n",
    "\n",
    "----------\n",
    "\n",
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###cv2.SimpleBlobDetector()\n",
    "The openCV function `cv2.SimpleBlobDetector()` implements a simple algorithm that performs all the necessary steps to detect blobs in an image.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "\n",
    "```python\n",
    "detector = cv2.SimpleBlobDetector()\n",
    "```\n",
    "\n",
    "cv2.SimpleBlobDetector() takes a single argument which is a parameters object. We'll cover this in the next section, so for now you can leave it empty and the function will use the default parameters which are set to detect dark circular objects in images.\n",
    "The function returns a *detector* object. The reasons for this extra step are complicated and we wont get into them here. Essentially it means that we can use a wide variety of feature detection methods, but we make sure they all have the same methods and attributes so that you don't have to rewrite all your code if you decide to change the method you use. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "\n",
    "```python\n",
    "detector.detect(image)\n",
    "```\n",
    "\n",
    "The detector object we create `detector` has a method `.detect()` that takes one argument, an image to run detection on. The function returns a list with one *keypoint* object for each blob detected. A *keypoint* is openCVs way of storing the results of feature detectors, and it contains the position of each feature in the image.\n",
    "\n",
    "The simpleBlobDetector detector expects to be given an 8-bit greyscale image. 8-bit refers to the way the number is stored by the computer. Computers work in binary expressing numbers in base 2 as a series of 1's or 0's. An 8-bit number is represented by 8 bits (1's or 0's), meaning that there are a maximum of 2^8 (256) numbers we can store. This includes 0, so an 8-bit number can take a value from 0 to 255. This value represents the intensity of the grey scale image at a pixel; 0 is black and 255 is white.\n",
    "We can make sure the image is an 8-bit greyscale image by setting the right flag when we load the image. Alterantively openCV allows us to convert images between formats, using the function `cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)`.\n",
    "\n",
    "----------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "`cv2.drawKeypoints(<image>,<keypoints>, <np.array([])>, <color>, <flags>)`\n",
    "\n",
    "We can mark the image with the detected blobs using the `cv2.drawKeypoints()` function. It takes 5 arguments... `image` is an image on which to overlay the detected blobs. `keypoints` is the list of detected blobs returned from `detector.detect()`. `np.array([])` is an extra output image we can overlay features on with the right flags. We will be putting the point on the input image so we don't need an output image, but openCV expects to get a numpy array here, so we pass it an empty array using `np.array([])`.  `color` sets the color of the markers added to the image in rgb format. `flags` takes a flag object that determins how the markers are drawn. The options we are interested in are:\n",
    "> **Flags:**\n",
    "\n",
    "> - **cv2.DRAW_MATCHES_FLAGS_DEFAULT** : Draws center points of blobs over image.\n",
    "> - **cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS** : For each blob draws a circle with area proportional to area of detected blob.\n",
    "\n",
    "###Challenge  - Detecting simple circular blobs\n",
    "Use the skills you've learned so far to write a function to detect the circles in the simple_blobs.png image.  The input to the function should be the file path, it should display the image with the detected blobs, wait for the user to press a key,  and then return the number of circles in the image.\n",
    "If you have time you can try using the [`cv2.putText()`](http://docs.opencv.org/modules/core/doc/drawing_functions.html) to overlay the count on the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Code Solution - Detecting simple circular blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detectBlobs(path):\n",
    "    \n",
    "    #Load the image\n",
    "    img = cv2.imread(path)\n",
    "    \n",
    "    # Set up the detector with default parameters.\n",
    "    detector = cv2.SimpleBlobDetector()\n",
    "\n",
    "    # Detect blobs.\n",
    "    blobs = detector.detect(img)\n",
    "\n",
    "    #Overlay detected blobs on the original image\n",
    "    imBlobs = cv2.drawKeypoints(img,blobs, np.array([]), (0,0,255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    \n",
    "    numBlobs = len(blobs)\n",
    "    \n",
    "    #select font for text overlay\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "    #add text to image\n",
    "    cv2.putText(imBlobs,str(numBlobs),(10,500), font, 4,(100,0,0),2)\n",
    "\n",
    "    # Show image with keypoints\n",
    "    cv2.imshow(\"Blobs\", imBlobs)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    return numBlobs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detectBlobs('simpleBlobs.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "Unfortunately Seals aren't usually perfectly circular dots in satellite images. Try running your blob detecting function on the `simpleseals.png` image and see what happens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It probably told you there were no seals in the image. This is because with the default parameters `SimpleBlobDetector()` is detecting all the blobs in the image, but then filtering them on the basis of color and shape and only returning those that correspond to black circles. We can change this  default behavior by changing the argument `params` when we first create the detector object.\n",
    "The argument should be a simpleBlobDetector parameters object. You can create this object like this \n",
    "```python\n",
    "params = cv2.SimpleBlobDetector_Params()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `params` object has an attribute for each of the avialable filters. You can get an idea about what these are by running `dir(params)` which will print the methods and attributes associated with the params object.\n",
    "Some of the attributes are boolean (True or False) and turn filters on or off, while the others set the values associated with the filters.\n",
    "When you change the filters from the defaults you get a whole new set of defaults that might give you weird results if you're not careful. Its best to make sure you explicitly switch off any filters you dont intend to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge - Detecting seals\n",
    "Modify your function from challenge 1 by turning off the filters and try to count the seals in the `simpleSeals.png` image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detectBlobs(path):\n",
    "    \n",
    "    #Load the image\n",
    "    img = cv2.imread(path)\n",
    "    \n",
    "    #Create the parameters object\n",
    "    params = cv2.SimpleBlobDetector_Params()\n",
    "    \n",
    "    #Set params attributes to turn filters off\n",
    "    params.filterByColor = False\n",
    "    params.filterByArea = False\n",
    "    params.filterByCircularity = False\n",
    "    params.filterByConvexity = False\n",
    "    params.filterByInertia = False\n",
    "    \n",
    "    # Set up the detector with default parameters.\n",
    "    detector = cv2.SimpleBlobDetector(params)\n",
    "\n",
    "    # Detect blobs.\n",
    "    blobs = detector.detect(img)\n",
    "\n",
    "    #Overlay detected blobs on the original image\n",
    "    imBlobs = cv2.drawKeypoints(img,blobs, np.array([]), (0,0,255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    \n",
    "    numBlobs = len(blobs)\n",
    "    \n",
    "    #select font for text overlay\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "    #add text to image\n",
    "    cv2.putText(imBlobs,str(numBlobs),(10,500), font, 4,(100,0,0),2)\n",
    "\n",
    "    # Show image with keypoints\n",
    "    cv2.imshow(\"Blobs\", imBlobs)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    return numBlobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turning off all the filters isn't really a great solution. If there are any other blob like regions in the image we're going to find those too. Try running your function on the `mixedblobs.png` image and see what happens. \n",
    "### Challenge - Detecting only seals\n",
    "Modify your function to detect only the seals in the `mixedblobs.png` image. If you have time try modifying it so that you can seperatley count both the seals in the image and the number of non-seal blobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detectBlobs('mixedBlobs.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detectBlobs(img):\n",
    "    \n",
    "    #Load the image\n",
    "    #img = cv2.imread(path)\n",
    "    \n",
    "    #Create the parameters object\n",
    "    params = cv2.SimpleBlobDetector_Params()\n",
    "    \n",
    "    #Set params attributes to turn filters off\n",
    "    params.filterByColor = False\n",
    "    params.filterByArea = True\n",
    "    params.filterByConvexity = False\n",
    "    params.filterByInertia = False\n",
    "    \n",
    "    # Filter by Circularity\n",
    "    params.filterByCircularity = True\n",
    "    params.minCircularity = 0\n",
    "    params.maxCircularity = 0.5\n",
    "    \n",
    "    # Filter by Area\n",
    "    params.minArea = 1\n",
    "    \n",
    "    # Set up the detector with default parameters.\n",
    "    detector = cv2.SimpleBlobDetector(params)\n",
    "\n",
    "    # Detect blobs.\n",
    "    blobs = detector.detect(img)\n",
    "\n",
    "    #Overlay detected blobs on the original image\n",
    "    imBlobs = cv2.drawKeypoints(img,blobs, np.array([]), (0,0,255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    \n",
    "    numBlobs = len(blobs)\n",
    "    \n",
    "    #select font for text overlay\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "    #add text to image\n",
    "    cv2.putText(imBlobs,str(numBlobs),(10,500), font, 4,(100,0,0),2)\n",
    "\n",
    "    # Show image with keypoints\n",
    "    cv2.imshow(\"Blobs\", imBlobs)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    return numBlobs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detectBlobs('mixedBlobs.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('mixedBlobs.jpg',cv2.IMREAD_COLOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv2.imshow('Blob',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def enlarge_image(image):\n",
    "    '''Adds a 1 pixel border around each image to help with contour detection.'''\n",
    "    \n",
    "    size = len(image)\n",
    "    \n",
    "    new image = np.zeros[(size,size,3)]\n",
    "    \n",
    "    # Add 1 to R\n",
    "    for i=1:size+2:\n",
    "        for j = 1:size+2:\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "replicate = cv2.copyMakeBorder(img,100,100,100,100,cv2.BORDER_CONSTANT,value=(255,255,255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detectBlobs(replicate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
